{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\my\\AppData\\Local\\Temp\\ipykernel_20976\\1789048249.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  accuracy_data_size_df = pd.concat([accuracy_data_size_df, pd.DataFrame([accuracy_data])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_sizes = [50.0, 60.0, 72.0, 80.0, 90.0, 100] # 30.0, 40.0, \n",
    "model_names = [\"lora_large_clip\", \"resnet50\", \"resnet101\", \"resnext50\", \"resnext101\"]\n",
    "results_path = r\"C:\\Users\\my\\Desktop\\Yolo\\yolo111\\lora_vit\\results\"\n",
    "\n",
    "# Initialize a DataFrame for accuracy_data_size.csv\n",
    "accuracy_data_size_df = pd.DataFrame(columns=[\"data size\", \"Ours\", \"ResNet-50\", \"ResNet-101\", \"ResNext-50\", \"ResNext-101\"])\n",
    "\n",
    "data_path = \"./data/\"\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    accuracy_data = {\"data size\": data_size}\n",
    "    for model_name in model_names:\n",
    "        folder_name = f\"mobileODT{data_size}%_{model_name}\"\n",
    "        valid_log_path = os.path.join(results_path, folder_name, f\"mobileODT{data_size}%_valid_log.csv\")\n",
    "        \n",
    "        # Read validation log\n",
    "        valid_log_df = pd.read_csv(valid_log_path)\n",
    "        \n",
    "        # Find the highest validation accuracy\n",
    "        max_valid_acc = valid_log_df[\"ACC\"].max()\n",
    "        \n",
    "        # Map model names to column names correctly\n",
    "        if model_name == \"lora_large_clip\":\n",
    "            accuracy_data[\"Ours\"] = max_valid_acc\n",
    "        else:\n",
    "            model_column_name = model_name.replace(\"resnet\", \"ResNet-\").replace(\"resnext\", \"ResNext-\").replace(\"50\", \"50\").replace(\"101\", \"101\")\n",
    "            accuracy_data[model_column_name] = max_valid_acc\n",
    "\n",
    "    # Append to the DataFrame\n",
    "    accuracy_data_size_df = pd.concat([accuracy_data_size_df, pd.DataFrame([accuracy_data])], ignore_index=True)\n",
    "\n",
    "\n",
    "# Save accuracy_data_size.csv\n",
    "accuracy_data_size_df.to_csv(data_path + \"accuracy_data_size.csv\", index=False)\n",
    "\n",
    "# For each data size, generate accuracy_epoch_{data_percentage}.csv and train_loss_epoch_{data_percentage}.csv\n",
    "for data_size in data_sizes:\n",
    "    accuracy_epoch_dict = {}\n",
    "    train_loss_epoch_dict = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        folder_name = f\"mobileODT{data_size}%_{model_name}\"\n",
    "        train_log_path = os.path.join(results_path, folder_name, f\"mobileODT{data_size}%_train_log.csv\")\n",
    "        valid_log_path = os.path.join(results_path, folder_name, f\"mobileODT{data_size}%_valid_log.csv\")\n",
    "        \n",
    "        # Read logs\n",
    "        train_log_df = pd.read_csv(train_log_path)\n",
    "        valid_log_df = pd.read_csv(valid_log_path)\n",
    "\n",
    "        model_prefix = \"Ours\" if model_name == \"lora_large_clip\" else model_name.replace(\"resnet\", \"ResNet-\").replace(\"resnext\", \"ResNext-\")\n",
    "\n",
    "        # Process train and valid logs\n",
    "        for epoch in train_log_df[\"epoch\"].unique():\n",
    "            if epoch not in accuracy_epoch_dict:\n",
    "                accuracy_epoch_dict[epoch] = {\"Epoch\": epoch}\n",
    "                train_loss_epoch_dict[epoch] = {\"Epoch\": epoch}\n",
    "            \n",
    "            accuracy_epoch_dict[epoch][f\"{model_prefix}_Train\"] = train_log_df.loc[train_log_df[\"epoch\"] == epoch, \"ACC\"].values[0]\n",
    "            accuracy_epoch_dict[epoch][f\"{model_prefix}_Test\"] = valid_log_df.loc[valid_log_df[\"epoch\"] == epoch, \"ACC\"].values[0]\n",
    "            train_loss_epoch_dict[epoch][model_prefix] = train_log_df.loc[train_log_df[\"epoch\"] == epoch, \"LOSS\"].values[0]\n",
    "\n",
    "    accuracy_epoch_df = pd.DataFrame.from_dict(accuracy_epoch_dict, orient=\"index\").sort_values(by=\"Epoch\")\n",
    "    train_loss_epoch_df = pd.DataFrame.from_dict(train_loss_epoch_dict, orient=\"index\").sort_values(by=\"Epoch\")\n",
    "\n",
    "\n",
    "    accuracy_epoch_df.to_csv(data_path + f\"accuracy_epoch_{data_size}%.csv\", index=False)\n",
    "    train_loss_epoch_df.to_csv(data_path + f\"train_loss_epoch_{data_size}%.csv\", index=False)\n",
    "\n",
    "print(\"Datasets have been created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
